# Sentence-Similarity-FastAPI
BERTs have the capability to embed the essence of words inside densely bound vectors. For the BERT support, this will be a vector comprising 768 digits. Those 768 values have our mathematical representation of a particular token.

After generating these vectors for the two sentences, similarity is calculated using cosine similarity
